{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quick NLG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abyki/reprotech-2021-2022/blob/main/NLG-%D0%A25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Viuf5RhzKG00"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6ki1-m-5UUA",
        "outputId": "b9e6af29-e65d-4689-911c-b8b1046414c9"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "32y1YQF15uBa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cxu1nJO4dGT"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB6rH4GenWpN"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers.optimization import  Adafactor \n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GZK-pXuKUw9"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CTSGvJQVChn"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "url = 'https://gitlab.com/shimorina/webnlg-dataset/-/archive/master/webnlg-dataset-master.zip?path=release_v3.0/en/train'\n",
        "urllib.request.urlretrieve(url, 'web.zip')\n",
        "with zipfile.ZipFile('web.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('web')\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "files = glob.glob(\"/content/web/webnlg-dataset-master-release_v3.0-en-train/release_v3.0/en/train/**/*.xml\", recursive=True)\n",
        "triple_re=re.compile('(\\d)triples')\n",
        "data_dct={}\n",
        "for file in files:\n",
        "    tree = ET.parse(file)\n",
        "    root = tree.getroot()\n",
        "    triples_num=int(triple_re.findall(file)[0])\n",
        "    for sub_root in root:\n",
        "        for ss_root in sub_root:\n",
        "            strutured_master=[]\n",
        "            unstructured=[]\n",
        "            for entry in ss_root:\n",
        "                unstructured.append(entry.text)\n",
        "                strutured=[triple.text for triple in entry]\n",
        "                strutured_master.extend(strutured)\n",
        "            unstructured=[i for i in unstructured if i.replace('\\n','').strip()!='' ]\n",
        "            strutured_master=strutured_master[-triples_num:]\n",
        "            strutured_master_str=(' && ').join(strutured_master)\n",
        "            data_dct[strutured_master_str]=unstructured\n",
        "mdata_dct={\"prefix\":[], \"input_text\":[], \"target_text\":[]}\n",
        "for st,unst in data_dct.items():\n",
        "    for i in unst:\n",
        "        mdata_dct['prefix'].append('webNLG')\n",
        "        mdata_dct['input_text'].append(st)\n",
        "        mdata_dct['target_text'].append(i)\n",
        "\n",
        "\n",
        "df=pd.DataFrame(mdata_dct)\n",
        "df.to_csv('webNLG2020_train.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ2uifxUnVgk"
      },
      "source": [
        "train_df=pd.read_csv('webNLG2020_train.csv', index_col=[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_dPYbsVK5zO"
      },
      "source": [
        "Немного обрежем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WpyPzBKyXf1"
      },
      "source": [
        "train_df=train_df.iloc[  :35000,:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgsIcgFgRCwN"
      },
      "source": [
        "train_df=train_df.sample(frac = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGfaigiqnZW5"
      },
      "source": [
        "batch_size=8\n",
        "num_of_batches=len(train_df)/batch_size\n",
        "num_of_epochs=4"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQDfdl3mxYf_"
      },
      "source": [
        "num_of_batches=int(num_of_batches)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_QyyxbkKXf2"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kfjkXbiKeyU"
      },
      "source": [
        "Проверка наличия GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHkcKfKRr1BC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28193caa-b742-492f-df1d-8fe8c593d67f"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    dev = torch.device(\"cuda:0\") \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    dev = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JaUpURdLAla"
      },
      "source": [
        "## Загрузим обученную модель и токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVAXjd6wsOM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b91fa4-c39d-462a-89a8-b367342704ab"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
        "model.to(dev)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (relu_act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx0uCmTvLJFb"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4oqM6giLLg4"
      },
      "source": [
        "## Инициализируем оптимизатор Adafactor с рекомендуемыми для T5 параметрами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KmOzTQj0E7L"
      },
      "source": [
        "\n",
        "optimizer = Adafactor(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    eps=(1e-30, 1e-3),\n",
        "    clip_threshold=1.0,\n",
        "    decay_rate=-0.8,\n",
        "    beta1=None,\n",
        "    weight_decay=0.0,\n",
        "    relative_step=False,\n",
        "    scale_parameter=False,\n",
        "    warmup_init=False\n",
        ")\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXw1NKtS1YV3"
      },
      "source": [
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(loss,value, max=100):\n",
        "    return HTML(\"\"\" Batch loss :{loss}\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss,value=value, max=max))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i7zx4DmC_ap"
      },
      "source": [
        "num_of_epochs=1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMe1hKshLgJn"
      },
      "source": [
        "## Транировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTvda_lWx2nC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e9d275fa-04d4-44da-87ed-626f07893d8a"
      },
      "source": [
        "\n",
        "model.train()\n",
        "\n",
        "loss_per_10_steps=[]\n",
        "for epoch in range(1,num_of_epochs+1):\n",
        "  print('Running epoch: {}'.format(epoch))\n",
        "  \n",
        "  running_loss=0\n",
        "\n",
        "  out = display(progress(1, num_of_batches+1), display_id=True)\n",
        "  for i in range(num_of_batches):\n",
        "    inputbatch=[]\n",
        "    labelbatch=[]\n",
        "    new_df=train_df[i*batch_size:i*batch_size+batch_size]\n",
        "    for indx,row in new_df.iterrows():\n",
        "      input = 'WebNLG: '+row['input_text']+'</s>' \n",
        "      labels = row['target_text']+'</s>'   \n",
        "      inputbatch.append(input)\n",
        "      labelbatch.append(labels)\n",
        "    inputbatch=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=400,return_tensors='pt')[\"input_ids\"]\n",
        "    labelbatch=tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=400,return_tensors=\"pt\") [\"input_ids\"]\n",
        "    inputbatch=inputbatch.to(dev)\n",
        "    labelbatch=labelbatch.to(dev)\n",
        " \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(input_ids=inputbatch, labels=labelbatch)\n",
        "    loss = outputs.loss\n",
        "    loss_num=loss.item()\n",
        "    logits = outputs.logits\n",
        "    running_loss+=loss_num\n",
        "    if i%10 ==0:      \n",
        "      loss_per_10_steps.append(loss_num)\n",
        "    out.update(progress(loss_num,i, num_of_batches+1))\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "  running_loss=running_loss/int(num_of_batches)\n",
        "  print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running epoch: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " Batch loss :0.40681567788124084\n",
              "        <progress\n",
              "            value='4374'\n",
              "            max='4376',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            4374\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Running loss: 0.4979317506296294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwVEDrdZ545G"
      },
      "source": [
        "## Лосс по времени"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7quhDpSxxTGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "aa8feffe-df1d-4773-886e-5cb5e7357b48"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "   \n",
        "steps = [i*100 for i in range(len(loss_per_10_steps))]\n",
        "  \n",
        "plt.plot(steps, loss_per_10_steps)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwU9f3H8dcnFyHhSAgBuQNyoyIQFQXxvq3aaltbtdban1p7ePRna6u1ra2/erS2tbaeba213kdtvS8QRO77FojcRxIgB0nI+f39MbObPRIIgSUwvJ+PRx7Znd2dmZ3d/cxnPt/vfMecc4iISPAktfUKiIhIYijAi4gElAK8iEhAKcCLiASUAryISEApwIuIBJQCvIhIQCnAy2HJzNaY2ZltvR4iiaQALyISUArwIj4za2dmfzCzTf7fH8ysnf9YVzN7w8xKzGy7mU0xsyT/sR+b2UYzKzezFWZ2Rtu+ExFPSluvgMhB5A5gLHAs4IDXgTuBnwE/BDYAuf5zxwLOzIYA3wOOc85tMrM8IPnArrZI05TBizS6ArjbOVfonCsCfglc5T9WC/QA+jnnap1zU5w3kFM90A4Ybmapzrk1zrnVbbL2IjEU4EUa9QTWRtxf608DeABYBbxnZgVmdjuAc24VcDPwC6DQzJ43s56IHAQU4EUabQL6Rdzv60/DOVfunPuhc24AcBFwa6jW7px71jk33n+tA+47sKst0jQFeDmcpZpZeugPeA6408xyzawrcBfwDICZXWhmA83MgFK80kyDmQ0xs9P9xthdQBXQ0DZvRySaArwczt7CC8ihv3RgNrAQWATMBX7tP3cQ8AGwE5gG/MU5NxGv/n4vUAxsAboBPzlwb0GkeaYLfoiIBJMyeBGRgFKAFxEJKAV4EZGAUoAXEQmog2qogq5du7q8vLy2Xg0RkUPGnDlzip1zuU09dlAF+Ly8PGbPnt3WqyEicsgws7XNPaYSjYhIQCnAi4gElAK8iEhAKcCLiASUAryISEApwIuIBJQCvIhIQAUiwD/04Uo+/qyorVdDROSgEogA/5dJq5i6qritV0NE5KASiABvGBrXXkQkWsICvH8ps/kRf2VmdnNilgWK7yIi0RI2Fo1zbgVwLICZJQMbgdcSsSzDu9KxiIg0OlAlmjOA1c65ZgfF2RdmpgxeRCTGgQrwl+NdsT6OmV1nZrPNbHZRUet6wpiBUw4vIhIl4QHezNKAi4CXmnrcOfe4cy7fOZefm9vkkMZ7XgaqwYuIxDoQGfx5wFzn3NZELcAr0SjCi4hEOhAB/ms0U57ZX7wSjYiIREpogDezTOAs4NWELgeVaEREYiX0kn3OuQogJ5HLAL9EoxxeRCRKQM5kVQYvIhIrGAFeNXgRkTiBCPCgE51ERGIFIsCbgXJ4EZFowQjwqAYvIhIrGAFeo0mKiMQJRIBPUjdJEZE4gQjwBjQovouIRAlGgNdwwSIicQIR4EHDBYuIxApEgDdd0klEJE5gArziu4hItGAEeDQevIhIrGAEeGXwIiJxghHg0YlOIiKxghHgzZTBi4jECEaAB9XgRURiBCLAoxq8iEicQAR4jRYsIhIv0RfdzjKzl81suZktM7MTE7EcDTYmIhIvoRfdBv4IvOOcu8zM0oCMRCzEDBoaEjFnEZFDV8ICvJl1BiYA3wRwztUANQlZFsrgRURiJbJE0x8oAv5uZvPM7Ekzy4x9kpldZ2azzWx2UVFRqxakC36IiMRLZIBPAUYDjzjnRgEVwO2xT3LOPe6cy3fO5efm5rZ6YYrvIiLREhngNwAbnHMz/Psv4wX8/U7jwYuIxEtYgHfObQHWm9kQf9IZwNJELMu8JSZi1iIih6xE96L5PvAvvwdNAXBNIhaiGryISLyEBnjn3HwgP5HLAI0mKSLSlICcyarx4EVEYgUjwCuDFxGJE4wAj2rwIiKxghHgNR68iEicgAR4jQcvIhIrGAEelWhERGIFI8BruGARkTjBCPAogxcRiRWMAK8zWUVE4gQjwGs8eBGROIEI8CiDFxGJE4gAb+hMVhGRWMEI8IrwIiJxghHgVYMXEYkTjACvGryISJxABPgkjUUjIhInEAHeDBqUwouIRAlEgAeVaEREYgUiwGu4YBGReAm9JquZrQHKgXqgzjmXkOuzGiiFFxGJkdAA7zvNOVecyAXokn0iIvGCUaJBCbyISKxEB3gHvGdmc8zsuqaeYGbXmdlsM5tdVFTUqoVoPHgRkXiJDvDjnXOjgfOA75rZhNgnOOced87lO+fyc3NzW7UQZfAiIvESGuCdcxv9/4XAa8DxiViOzmQVEYmXsABvZplm1jF0GzgbWJygpalAIyISI5G9aLoDr5lZaDnPOufeScSCvAxeIV5EJFLCArxzrgAYmaj5R7IDsRARkUNMILpJJplpLBoRkRiBCPBqZBURiRecAN/WKyEicpAJRoDH1MgqIhIjEAEeZfAiInECEeC90STbei1ERA4uwQjwGg9eRCROMAI8OtFJRCRWMAK8avAiInGCEeBRP3gRkVjBCPAaD15EJE4wAjzK4EVEYgUjwJspwIuIxAhIgFcvGhGRWMEI8KgXjYhIrGAEeI0mKSISJxgBHvWiERGJFYwArwxeRCROcAJ8W6+EiMhBJuEB3sySzWyemb2RwKUogxcRiXEgMvibgGWJXIBpvGARkTgJDfBm1hu4AHgyoctBNXgRkViJzuD/APwIaGjuCWZ2nZnNNrPZRUVFrVqIavAiIvESFuDN7EKg0Dk3Z3fPc8497pzLd87l5+bmtm5ZuiariEicFgV4M8s0syT/9mAzu8jMUvfwsnHARWa2BngeON3MntmntW1GkjJ4EZE4Lc3gJwPpZtYLeA+4Cnhqdy9wzv3EOdfbOZcHXA585Jy7ch/WtVlmRkODQryISKSWBnhzzlUCXwL+4pz7MjAicau19xTeRUSitTjAm9mJwBXAm/605JYuxDk3yTl34d6uXEuZRhsTEYnT0gB/M/AT4DXn3BIzGwBMTNxq7R1vLBoREYmU0pInOec+Bj4G8Btbi51zP0jkiu0NjQcvIhKvpb1onjWzTmaWCSwGlprZbYldtZZThUZEJF5LSzTDnXNlwCXA20B/vJ40BwWNJikiEq+lAT7V7/d+CfAf51wtB1HSbKbx4EVEYrU0wD8GrAEygclm1g8oS9RK7S2NRSMiEq+ljawPAQ9FTFprZqclZpVaQWeyiojEaWkja2czezA0KJiZ/Q4vmz8omCK8iEiclpZo/gaUA1/x/8qAvydqpfaWN5qkIryISKQWlWiAI51zl0bc/6WZzU/ECrVGkoGGohERidbSDL7KzMaH7pjZOKAqMau09zRcsIhIvJZm8DcAT5tZZ//+DuDqxKzS3tMFP0RE4rW0F80CYKSZdfLvl5nZzcDCRK5cS6mbpIhIvL26opNzrsw/oxXg1gSsT+t4V90WEZEI+3LJvoMmqoZWRHV4EZFG+xLgD5poGkrgFd9FRBrttgZvZuU0HcgNaJ+QNWoF83N4xXcRkUa7DfDOuY4HakX2RWMG7ziIKkciIm1qX0o0B41wDb5N10JE5OCSsABvZulmNtPMFpjZEjP7ZeKW5f1XDV5EpFFLT3RqjWrgdOfcTn8s+U/M7G3n3PT9vSCzUA1eEV5EJCRhAd55BfGd/t1U/y8hEVgZvIhIvITW4M0s2R+UrBB43zk3IyHLCfWiUYAXEQlLaIB3ztU7544FegPHm9lRsc8xs+tC48wXFRW1ajnhDF4lGhGRsAPSi8Y5VwJMBM5t4rHHnXP5zrn83NzcVs2/8UzW1q+jiEjQJLIXTa6ZZfm32wNnAcsTsyzvv+K7iEijRPai6QH8w8yS8XYkLzrn3kjEghpr8ArxIiIhiexFsxAYlaj5R1IGLyISLxBnsoYogRcRaRSIAG9K4UVE4gQjwPv/1U1SRKRRMAK8zmQVEYkTjADv/1d8FxFpFIgAn5SkbpIiIrECEeBDGXyD4ruISFggAjwaLlhEJE4gAnz4In2K7yIiYcEI8OoGLyISJxgBXuPBi4jECUaA13jwIiJxghHg/f/K4EVEGgUjwKsGLyISJxgBXuPBi4jECUSAR2PRiIjECUSAtz0/RUTksBOMAG/qJikiEisQAd4fa4wGRXgRkbBABHj1ohERiZewAG9mfcxsopktNbMlZnZTwpalXjQiInFSEjjvOuCHzrm5ZtYRmGNm7zvnlu7vBSmDFxGJl7AM3jm32Tk3179dDiwDeiVqed5yEjl3EZFDywGpwZtZHjAKmNHEY9eZ2Wwzm11UVNTa+fu3FOFFREISHuDNrAPwCnCzc64s9nHn3OPOuXznXH5ubm7rlhGeV+vXU0QkaBIa4M0sFS+4/8s592riluP9V3wXEWmUyF40BvwVWOacezBRywGNBy8i0pREZvDjgKuA081svv93fiIWpPHgRUTiJaybpHPuEw7QMDGqwYuIxAvWmawK8CIiYQEJ8F6E11g0IiKNghHg23oFREQOQsEI8BouWEQkTjACvP9fvWhERBoFI8CrkVVEJE6wAnzbroaIyEElGAFe48GLiMQJRIBHGbyISJxABHidySoiEi8YAV7jwYuIxAlGgPf/K4MXEWkUjADvR/gGBXgRkbBABPjO7VMB2F5R08ZrIiJy8AhEgO/fNROAz4srWLKplAal8iIiwQjwHdNTye3YjtfmbeCChz7h8SkFbb1KIiJtLhABHrws/rOtOwGYu3ZHG6+NiEjbC0yAH+CXaQBq6xvacE1ERA4OgQnwWRlp4du19arBi4gkLMCb2d/MrNDMFidqGZEy0pLDt2uUwYuIJDSDfwo4N4HzjxIV4OsU4EVEEhbgnXOTge2Jmn+sjLSU8G3V4EVEDoIavJldZ2azzWx2UVFRq+ejDF5EJFqbB3jn3OPOuXznXH5ubm6r5xNbgy+trOW5mes0RryIHLbaPMDvL5Elmsqaem5/dSE/eXURSzaVteFa7T9feWwa97y5tK1XQ0QOIYEJ8O0jMviyqlo27KgCoDqmXFNT19CqrL6ypo5bX5hPYdmufVrP+gbXqqEUZn6+nSemfL5PyxaRw0siu0k+B0wDhpjZBjO7NlHLAshs1xjgq+sa2LazGoCd1XXh6c45ht/1Dt95Zu5ez/8/8zfx6ryN/P6Dlfu0nif83wec+8fJe/WayB2Sc05lJwGgorqOsx78mLnrdlBb38CkFYVtvUpykElkL5qvOed6OOdSnXO9nXN/TdSyADJSU6Lubyr1Mu2Syhp21dYzZ+0Opq7aRl2D450lWwBYtrmMCfdPDO8MYv3m7WXc+K85AFTV1gOQ7G+xddsqWVVYvtt12lFRw4YdlVHTinfWhIdUaKmKmvrw7R88P58fvrigxa+9582lfLB0614tD+DFWev5vLhir1+3vzjnmLduh3Zmu7FwQykrC3dy79vLue/t5Xzz77OYt07DdEijwJRoMiIy+NRkC98urarl/ndWcOkjn3LlX2cAMKhbBwAe+3g167ZX8tHyQhoaHF99bBq/fqOxzv3YxwW8tcjbGYQCfLsUbzkTHpjImQ/uPhM//XeTGH/fRP4+9XO+/sT0vXo/izaUho8+dkQMgzx//Q4+28OOJdITUz7n20/P3qtl19U38KNXFnLRw5+wsaSKsl21e/X6/WHe+hK++JdPmXOQjCt079vL+fnrrT9n7/X5G3l2xrr9uEbQ4O/8DPh09TYAqiKSAZGUPT/l0BDZi+boXp2Zu64EgJLKWtZt9zLRC47uwZy1O8IXCMls5739KSuLue3lhQDM+Hw7V4ztR1LjPgLnHEXlXpYf28e+uq6el+dsYETPzhzbJyvqsR2VXmD85X+9ncbUVcUtei9lu2r5wsOfcP7RR/CXK8ZQUtkYYDeXtLwNoLXdRct2eTuW8l11jLv3I04f2o2/ffO4Vs2rtULbe932StZuq+T8o3tEtbMcaI9+vBqA1OQkZq3dwevfHbdXr7/p+fkAfP2EvvttnULBPMmMrX7bUHlESVIkMBl8ekrjj/+4vC7h2yWVtRSVVzNhcC5/vmI0Jw3MoaLa+2G0T/Ve858Fm6LmddpvJ3HKA5PC98t21YV/QDsqa/nrJ42NnasLK7jjtcVc8uepUfPYVRufSV3x5IwWvZfVhV4JJ9QDaEdlYwZf1+AorWxZRl1a1fzzynfV8snKYgbf8Tari6JLRrGvm16wrUXLAy/7n7++pMXPb06FH6jeX7qVH760gDv+vSj8WG19yxvKd1bXccFDU1i8sXSf1wngyU8+Z8F+eH8t9fS0Nbw0e32Tj4U+p+QkY5t/lBf52ZVW1u6XEterczdQWN50YrFyaznffXbuPp97Mnfdjv1ywZ5dtfXc9Pw8NpVU7fO8Es05x3efncvE5YlrOwlMgE+KSLmjA3wNReXV5HZoB0BmWgoVNV7wCP3fk5dmrw+XaqasLOJXEWWcac0Ev48/2/1JW7tq6/ntuys4/beT4n48q/wAn5PpDaAWGeDBy9Ja0hMnsrRy8cOfcMsL88P3v/7EDK786wxq6ht4P6ZGXxYT4NNT4zPnBetLeGvR5rjpD09cxSV/nrrPATUU4Df6P9TJn3lHP845Bt3xNj99rWXlkllrtrNkUxn3vr282efUNzh+89YyPttaHl52cwEtpLyVZauGBkdVTT11LTzb+q7Xl4SPLmOFgnlkMhH67J6dsY6Rd7/HpBWtP3kQvKuk3friAr79j6bLfP/70gLeXLiZRS38vD9YujWuDam+wfGlv3zKlU/OoLSytsnkqKUmLi/k9fmb+HUTXYpr6hq4/53lrf7s9rfNpbt4c+FmrnlqVsKWEZgAH+m4vC508YPj4k2lbCrdRW5HP8C3S6HSz+BLWpgJ//rNZeHbsa+Z3EQgr6iu4/p/ztntPLdV1PDwxFUUFFewfHN0TX2Vn1F3TE9tcpnOeeWTSCWVNXy6OroEFJnNLdhQymvzNobvR/4gY7/wsRn89ooaSmJ2Mhf/eSo3/svrjTR7zfbwTmmpf9TRVAPtqsJy/velBeFs77V5G1i2uenzFHb6n1FBkTef4p3VVNbUhUsQz81ct9uscVNJFSff/xEbtnuN3LsbvmLZ5jIem1zA2b+fTE1dA19+dBrH3/Nhs88H2Fq2izlrd8S9zyuenM6rczc0+7qSqlqG3fUOt7agoXxPJb3Q5xSZ+Ya+Kw++/xkAN78wn6emtr57behzD32+sfY0cmtdfQN5t7/JM9PXAvDtp2fzytwNUQlKKIFZurmMkXe/x1cfb1l7VUOD42f/XhyVTJhff62MaIuYuqqYvNvf5IF3l/OXSat56MN96wnXGrtq6+M6cyyNOEdnS+m+db9uTuAC/MmDutI5I5U5d57JoG4dwj1WwgE+LZma+gaKd1bvVS+R288byokDcuKmz14TPdzOxOWF4eD5o3OHNDu/goiySKj8U9/g+PPEVUwv8OZZvquWn/17cbj+Gyk2CF/7j9l8/YkZFJbv4vX5G3lp9vomSzQrtpTzt0+if/CrC6O3Q+TrhvXoBMA/p61lysoifv3GUuojfpzVdfVc9ug0zv/jFKCxXaOwPL5n0veencfLc7ygvnBDCbe8sCCczc38fDtXPDmd6jrvhxnK4CO7ud728kK27WwMZgs3xJdKQiWJf8/fyPrtVfxlkrft6iLWecWWcn7y6iLKd9XS0OCiAsTCDSUs9Xc6oSDUVLa9uXQXlz7yKaf9dhLgHWn89LVFTF21jVtfXIBzjsmfFVFUXh3V8Llii7czjy0LRnp2xjrG3ftRVEmvpLImrjQV+pzWba+MmuacC++0S6tq+cV/W3+CXKgdqbqugc2lVeHPJ6Suwds2kUeLs9ZsD2+70Osjj3oB7n93BXm3v0lVTT3FfuALtY01VQJ7cdZ6vv/cvKhp63dU8s/pa6OOLkLrEblDf2Oht61DR9WVNfVMW72NS/48Ne797E5tfcMej5ydc7w2b0PU9zbv9jcZ+rN3GPPrD3hySkF4hxyZ3Jz1+48T0kAemEZWgIL/Oz9828y4dnx/bn/Vq91GZvAAx93zAbsrTw7omsk3x+Vx1+tLAPifkwdQWFYdV5KJ7MI4a812rnlqVriB9oKjezCsRycy01L4ymPTote1qDGo3vbyQv76yefceNpAHnh3RXj63HUl4cbiWJFBuLquPtzb5LGPC8JtBH+8/Ni41132yKfhLHhknyxKK2soKG6+Bn/3xSO44Z9z+J2fEYJXhw75YKlXPwwN0Rz6Ya3dFr/z3OLvyNZur2SK/2PrkO59Hre8MJ+NJVUs3FDKcXldon4gAKP7ZjFt9baoLGhT6S5q6hpITTbeWLiZF2evp7CsmndvmUCSHy1CO4SNO6rYUrqLIzqnc84fvN5PvbPb8/BHq+iXkxGe5+yIXjslVbVsr6hp8kjh6Wlro+7f9Ny8qNfO/Hw73/jbTAAuObZnePq0mKOsgqKdvDZvIzedMYiU5CQaGhw/fW0RsRZsKOU7z8zhljMH8z8TBgCNn1Pkzmvp5jI/cEWvc2llLZ+uLuY7/5rLWz84meE9vR23c445a3fQqX0qg7t3xDnHlJXFjB/YlaQkC2fw9Q2Ocfd+xKi+2Tx/3VhS/f7CdX4GHyoNTVxeyDVPzeLUIbnceOpAumR6R6GxQ3iHkpZhd73DyN6d/XWJe9thP3rFK1Pd88Wj6OQf2YZ+QyVVNdQ3OP6zYGP46KmmroGd1XVMWlEYnm9oM/1rxjr+5fdo2uifEFlUXs0JA3JwzrFoYylH9ewcLvtuLdvF7a8sZOKKIr48pjcPfHlk1PvYXFLFjspaHvraKD7bupNbXljAmcM28+TVx8WVm3795jKem7mON39wcri7NsCFx/RMSCeCQAX4yDo8wOXH9+XD5YW8v3Qr6SneFzJ0QlToQ+/QLiUumJjBR/97KjV1DeEAn5xk9OicvtvlvzLH+3KFvkh9sjPol5NJZUSt//dfHcktLyyIyuABlm8p5xf/WRI3z/TUJO68YDipycaPX1mEmbfuj368mj99bRRJScb8iJ1AZANwUyWoyF4WN50xkDlrd/DYxwWUVtbSOcP74YSyoOW/Opf01GReu3EcEx6Y2OR7fvIT7/q3nfxAHcrGpq3exhVPTmf8wFyO79+Fo3t1DgekgqKd4Ybd6roG1hRXsK3Ce92C9SVkpCXHtQucM+IIfvP2ci57tHFH+QM/o+vaIY3iiMx+R0VNOOCEAsuWsl2M/c2HLLu7cQTrRyatpqq2nuVbyjlxQA5bynYxe01jkC4qrw7vDGLFrl/ozOmQWRFHdpMiyngPfbQqfLu6rp7HJxfw/Kz1dOuUzlVj+zFvfdPdQu94bRGVNfXc89Yyvn1yf8ws7gitU3pKs91KR/3qvfD3cuKKQob37MSu2nq+/sR05q4rYUj3jjx21RhmrdnObS8v5LQhuZw6pBv3v9PYdtHgYM7aHcxdu4MTBuTw/tKtFPhHwaVVtZTvqmXySu+9TlpRxPrtldx76THA7oP3gg3x9fu6+gYWbSxlRM/OpKU0FhqO+cV7fHDrBLIy0sJlo/oGxzuLt3DLC41lr7Iq78zz95ZuZaTfu2399uhzUsDL5i/80ycArLn3Am57eSEvz9nAT84byvWnHOltr+WFTPTbMl6as4GC4gpevP5Eqmrro9p2bjtnSLhx94NlhSzcUBJOKCOtLqrg71PXsGRTGfdfegylVbVcdWK/5jfQPghUgG/KPV88ii4ZaYwf1BUgboOnpybHBfiO/nPSUpL47mlHcuqQbgCcMiSXe95qrMdnZaRGBdGX5zTWXvvlZIR3OO0jGimP6ullK6/ObayHhzTVi2D8wK5cObZf+CzFvJxMPi+u4M1Fm3l/6VYe+PIx4dddfGxPXp/feOi/son+8kkGj1+Vz/XPzOHoXllkZ6Tx54mruePfiygsq+Yf3zqe0qpa0lKSwo2rfXMyuOGUI5ssFc3zdy5lu+p4Yda6cGlmZeFOVhbuZOoq74jnV5ccFf6RFxRVsGZbpf+eqzn9d5PCwSeyvSMkOcnIz8uOmx56P5HBHeDD5YXN1jT/8EHjkUjk535cXjabSnfxUUSPhk2lLeuJ4ZwL79hC/rNgE/27ZnLqkFz+PnVNk6+btKKIFP+cjRdnredLo3qFy3Mhy+4+lzG/fj9qB/Lmos2cPCg3LsC3T0sOd3EF73sXOn8jsrJQVF5NdV09SzeXMXddCXk5GazYWs6pv51E3y7e0czEFUXhoBaS3y+b2Wt38OD7n1FaVcvyLY3fr7teXxJOhkJWF1Xw6aqW98CKNHvtDi5/fDpfye/N/ZeNpFdW+3CD+zPT1/HUp2vCz62tdzw3M/ocg82lVazwG81DJZ/YoxqIToKq6+r5j//7eWJKAdeO709KclJc4jhn7Q7WbqsI1/tDnpm+NrzDA7jo4eiedZE+/sz7nl10bM8mOzHsL4Grwcfq1jGd+y47JjwYWWZadIC//Lg+4d4qIaHGTYDbzhka7pUTOkEqpIt/mcDj/OBT1+D45kl5vHPzyVH9xiO/CJ3be/PeU3/lPL9s0LeLd63Z0I5pWI+O4efU1Ddw0/Pz+eV/l5KdkcpPzhtG5/apXOH3tV68Mb4B88xh3TlzeHdW/9/55HZsx8jeWfTonM4bCzczc812Xp6znjXFFeHD4JDQDz/kB2cMCt/+5kl5APz4lUUUFFWEs/lID324kuPzujBhcC7z1jd2idtSuiscfI7P68KpQ+JHFO2YnsKInp3p2MR8H7lyDL+LOGQGeHzyajY0003usckFTU4/YUAO+f2yo3ay85rJhj+4dULU/e0VNVFlEoDPtu5kVJ8semdHb7dB3Trw+FVjaJ+azPX/nMMz073AtGhjKSN+/i6vz9/IkbmN1xdun5ZM907ekePPLhwOeG0ZP3xxflyjXVe/p1jIU9ccx/1+Bh3pvSVbGHLnO/zGT1a+elxj3/x1TWS5Iecd3QPwzhWJDO678/S0NVH3k2OCZXPeW+IdIf173iZKK2ujauWvRCRSKf78PllVzNAjGn8bZbta1kMusjvlnDU7qKlv4Iyh3SjeWcPiTWU8O2Nd+Ggwcv7Lt5TH7dQfm1wQd2QXafzArrzx/fEAzA4n4OkAABKESURBVF1bQsd2KQkN7nAYBPhYkRn87748klvOGsycn50V9ZymAgl4gXrq7aeT6dfKJgz2gtEPz25sTO3fNZOhR3TiyNzoncFLN5zIxP89lW6d0rn1rMFx87774hH075oZLgOFsoZe2e299fZ3TMf2yWLsAC9Qnj60G0f18mqpDQ6O6JzOgp+fzTXj+gPE9Ue/8dQjefCr0XX5pCTj3KOOCN//2etLeHfJVmJ/h6H1CLnOrwNDdLdUgK/k94l7f0Xl1fz4vKEM69GR9du9H9XIPlnhXhi/uuQoXrh+LE9dczz3XxYdlDr4P4SFPz87br7De3Ti0jG96dPFW7/Th3bjs607mfn57q81M2FwLr2z2/Pt8d62GtU3K+4oIbKcAvDIFaN55toTGNitY9T00ElMscYemUPviO32q4tH8O7NEzh7xBF8+MNTSEuO//l9tnUnx/fvwv2XHsML140F4P++eDRDj+jIZaN7c7y/rT9YVsjGkqrw0aa3fmN49caTwvf752Zy2ZjejOobfQJeaBiPWWt2kJ6axJnDujW5/pH+ePmxfCW/926fE/ouhuT3yw73zwfYsKMyfPbtnoQaoWvqGxh593sU76zhhlOOZNzAnHBylJWRyivfOSlcwvnOqUfGzadXVvu4aZFCtX3wjvwAvjTae59XPDGdn762iA+XFWIGN5/ZmNQ8N3Nd1M7h7otH7PE9HZfXhaN6dSYnM42a+gZyOqTt8TX7KvAlmliRZ7wO69GpyYwiNnuN1CurPd07p1NQVMF5Rx3BbecMidppDIjIviJFBsEfnDEo3I3trOHdeX/pVr5xYh7fODGPsx78GIDbzx3KU5+u4dLRvQCv5HN8XhdOGdyN6yY0fpGdc9z3zoqoH3Hv7PbhWn1OZlr4R3bt+P50aKImeMHRPfj71DV0yUwLZ7D3xWR+kYFq6BEdwzu5lCQjO7Nxex3VqxNXn5THF0b2pG+XDNbvqOSih6dyxtBujOmXHT7MBhh3ZE748HlUn6zwkU7vmB9l6Igq8kgodMge+gEn+49dMy4vXGYJlRQAvn/6QP4UEbB/edEIenROJzU5iZvOHERGWgoDukbvlGMN69GJvK7xn+8nq4r5+gl944YiOOnIHMqqGjPJfjmZ4R13z6z2XDqmF8/NXM/g7h2ixifK79eFS8c0BtMTj8zhnZu9o4bHrhrDIx+v5vHJBdTWO75zav9wt7++ORn0jWgwzslsR1KS8fINJ1G8s5r3lmxh3roSXo3oLpudkUb/rpkM6JrJWSO6M7pvdpNdfC8+ttceT5p67Kp8VhXuJC05iYrqOrZVVEc1PI+/r+l2nL9/8zh+8/YyPtu6k07pKSQnGcU7q+neqR0XHtMz3K7UJTOVo3tlMXXVNrp2SGPWHWdiZozum8WiDaWcM8JLVHp0TufOC4aTlpLEtNXb+FsLu4n+9ZPPGditQ7icG+pAMa1gG53SUzhjWHduO2eI36OsmMIyL4OfdceZ5HZsx6g+2Xzh4U+anb/D236DundgW8H2uCOuRDjsAnxkgIvsPRHpi35QbU4omGS2S4mr6fdvIgA05a9X51NaVctFI3tG9SV+6GujeGJyAacP7cbZIxoz68x2Kbx4w4lx8zEzbj9vaNS09NTkcBfRa8bl8dv3vJ1JqDwUKz+vCy/fcCIbS6q46fn55HZsx2lDo7O6I3M78N/vjWdoj47hHhT/+vYJ5HXNDI/98+iVozn3KO8wvo9f0snOTOP568Yypp+XHR/VszHLixzaIfKIJ/ZoITJLffTKMWyvqOHMYd3YWlYdDpjZmWms2VZJ907p3H/pMUwv2MY9Xzw63EsjNovt2iEtfHgc2oEkJRnjBuYwddU28nIyGNajEzV1DeHMLiujcfsd0SmdLWW7GNMvm+6d2nHXhcPDAf6uC4czdVUxvbMzqMxsDPCRI55GbqOjenbmuLwu4Z4dsUdEkbIz07j6pDwe90tNx+Vlc/2EAeFaPnify+SVReHkJTnJ6N4pnatOzCMrY1M4wD965Wi6d0onJTmJj/731Lj3Fiu25gzwxvfHhxspe3RKj8qYY8+Qbs5pQ7uxdlsFv/jvUvrmZFBX79hRWctpQ7rxswuHM2lFIauLKsjKSOMr+X1Yu62C4/K6hNfnzguGU7SzmvTUZD6+7VQ6pqeGz4M5c1g3vn/6QBZvKuWqv84ML3PBXWcz8u73ALjlzMH83m+bufuiEU3+Tjq1TyU1OYnvnjaQc0Z058wHJ7NiazlJRnhZR/fuzM+/MJwendO5oYkRa/v45boh3TsyvWC7MvhE6NMlg/85uT8XjewVFZyPzM1kdVEFC39x9m4zeGisIyZFfOG/NKoXr87bSM/Ouz8kDDljWPfw7YhRFhjWo1NcGaU1vjymD/e8tYwTj8zhvVsmMGftDlKaKAmE5Od1obtff22qvz94X+BI4wZ2Dd9ec+8Fzc57bMT88nIyOaF/F64Y2y9cn77k2OguYj0itmG7lKSokllkOalbp8ZeTQ9dPornZ61jYG4HBnfvyFeO88pEM396Bu1Sk+O6bTZ1JBOaz2OTC/jh2YNpl5JMXX0D9769nJF9ssjKaPxB/ud741i7vbLJYPyt8f35ll/6ibwQTWwyECrH7aqr58GvHktheTULN5SEy03N6ZXVngFdMykorqBPdgY/OX9Y1OPjBnaN+mwiRR6JhXbGsV68/kQWbyrl/KN7sG1nNbvL23tltQ8fTcU2Rg6ISHayM1LDfeKbkuqXWfJyMunaoR3Lt5Rzg9+LJSeznRfg26eSlZHGI1eOiXrtUb0av5f9cqITLDMjOzONkwflcuOpR7KldBcrtpbTqX3jZxFKPgBG+7dPHtSV6QXbOGVwLh8sK4yKCQO7deTkQV2ZsrKYnA7toqoAofLoF0b2pLauIdwV8h/fOp4J/pHBoO5eiU8ZfAIkJxl3XDA8bvrLN5zExpKqPQZ38GrMd7+xlO6dGj+g+y47hp9/YUTcl7ytfPvk/owf1DV8otLg7h338Apv5/fMtScwul/WHp/bWklJxgvXNx6JfHDrKVGNiuD1XvrBGYMYP7Ard72+mCP20D0VvHW/7ZyhcdNDO4EuMQ3pTWWjADkd2vHTiICZkpzEnRfGf1+6dUqP2sHsTlpKEjV1DVG9qQCy2nvrlJzkBbe7LhxO2a7aZtct0smDurJhRxU991BjjhV7dNSUyFJPTjNB6NErR1NUXk12Zhrv3TIh3B8+kpkxqm8WSWY8csVovvzYNNZua7oRd1et18NleM9OfGtcf64+KS9cDuuV3R7W0OL6fXN+dG789wOiE5fQUd0T38jHOXhySgEfLCuM6qoZWs8pK4vp1rHp7fOnr40CvBPgyqpqw79DaPwtNrdt96fDLsA3JzszjezMlh0yXTMujyvH9ov60FOTk+iccfC0WZtZ1JeqpUL1xwNlYLem696hhuinrz0+LjC2Ro/O7fnSqF6kJie1+HPeX+679GhueWFB+GS7kJMHdeX6UwZwrZ/19enSdMmwKbeeNYRLRvWKCzx7krufgsrIPlnhI62m+nqHvHZj46ibo/tms3ZbJRMG5zL5syLOHNYtfKTz9eP7UlVTx7Xj+9MuJTmq1HnnBcPolJ4S7q68vzXV6ysU6Pv7yUfseFAXjezJ0k1l/LiZnUZI6Agn0tAeHencPpVhR+w56dpXdjBdUCE/P9/Nnr13Y5eLHCw+L65g5666uFLWweaeN5dydO8sLhrZc89PjpF3+5sArPj1ueFrI7TUXa8v5ulpa7nrwuEMOaIj+XnZez2P/em1eRuoqmng6yf05d0lWxjcvWNcG9rSTWWc/9AUMtOSWRJxkty+qqtvIDnJWnS0tidmNsc5l9/UY8rgRfaTljawt7WmSpQtNaxHJ5ZtLmtVYA7VnOsaGpptIziQvjiqsafSOREdGiKFPtPmOii01u7aw/brcg7IUkQkEF64fmzUgG9749sn96d8Vy1Xjk3MafmJ0D4tmd9/dSTH9mn6TOqDXUJLNGZ2LvBHIBl40jl37+6erxKNiMje2V2JJmHHCWaWDPwZOA8YDnzNzFp/bCgiInslkYWg44FVzrkC51wN8DxwcQKXJyIiERIZ4HsBkReT3OBPi2Jm15nZbDObXVS0b5cXExGRRm3ecds597hzLt85l5+bGz+SoIiItE4iA/xGIHJYwd7+NBEROQASGeBnAYPMrL+ZpQGXA/9J4PJERCRCwvrBO+fqzOx7wLt43ST/5pyLvyadiIgkREJPdHLOvQW8lchliIhI0w6qsWjMrAhYu8cnNq0rULzHZx1etE2apu3SNG2XeIfCNunnnGuyh8pBFeD3hZnNbu5srsOVtknTtF2apu0S71DfJm3eTVJERBJDAV5EJKCCFOAfb+sVOAhpmzRN26Vp2i7xDultEpgavIiIRAtSBi8iIhEU4EVEAuqQD/Bmdq6ZrTCzVWZ2e1uvTyKY2d/MrNDMFkdM62Jm75vZSv9/tj/dzOwhf3ssNLPREa+52n/+SjO7OmL6GDNb5L/mIdsfF4pMMDPrY2YTzWypmS0xs5v86Yf7dkk3s5lmtsDfLr/0p/c3sxn+e3nBHz4EM2vn31/lP54XMa+f+NNXmNk5EdMPyd+cmSWb2Twze8O/H/xt4pw7ZP/whkBYDQwA0oAFwPC2Xq8EvM8JwGhgccS0+4Hb/du3A/f5t88H3gYMGAvM8Kd3AQr8/9n+7Wz/sZn+c81/7Xlt/Z5bsE16AKP92x2Bz/AuLHO4bxcDOvi3U4EZ/nt4Ebjcn/4o8B3/9o3Ao/7ty4EX/NvD/d9TO6C//ztLPpR/c8CtwLPAG/79wG+TQz2DPywuKuKcmwxsj5l8MfAP//Y/gEsipj/tPNOBLDPrAZwDvO+c2+6c2wG8D5zrP9bJOTfded/ipyPmddByzm12zs31b5cDy/CuN3C4bxfnnNvp3031/xxwOvCyPz12u4S218vAGf6RysXA8865aufc58AqvN/bIfmbM7PewAXAk/594zDYJod6gG/RRUUCqrtzbrN/ewvQ3b/d3DbZ3fQNTUw/ZPiH0KPwstXDfrv4pYj5QCHeDms1UOKcq/OfEvlewu/ff7wUyGHvt9fB7g/Aj4AG/34Oh8E2OdQDvOBlbXhZ2mHHzDoArwA3O+fKIh87XLeLc67eOXcs3jUYjgeGtvEqtSkzuxAodM7Naet1OdAO9QB/OF9UZKtfRsD/X+hPb26b7G567yamH/TMLBUvuP/LOfeqP/mw3y4hzrkSYCJwIl5JKjR6bOR7Cb9///HOwDb2fnsdzMYBF5nZGrzyyenAHzkctklbNwLsyx/ecMcFeA0eocaNEW29Xgl6r3lEN7I+QHRj4v3+7QuIbkyc6U/vAnyO15CY7d/u4j8W25h4flu/3xZsD8Ori/8hZvrhvl1ygSz/dntgCnAh8BLRDYo3+re/S3SD4ov+7RFENygW4DUmHtK/OeBUGhtZA79N2nwF9sMHdj5eD4rVwB1tvT4Jeo/PAZuBWrz63rV4NcEPgZXABxFByYA/+9tjEZAfMZ9v4TUMrQKuiZieDyz2X/Mw/hnOB/MfMB6v/LIQmO//na/twjHAPH+7LAbu8qcPwNthrfIDWzt/erp/f5X/+ICIed3hv/cVRPQgOpR/czEBPvDbREMViIgE1KFegxcRkWYowIuIBJQCvIhIQCnAi4gElAK8iEhAKcDLYcnM7vBHW1xoZvPN7AQzu9nMMtp63UT2F3WTlMOOmZ0IPAic6pyrNrOueCeofIrXP764TVdQZD9RBi+Hox5AsXOuGsAP6JcBPYGJZjYRwMzONrNpZjbXzF7yx73BzNaY2f3+WPEzzWygP/3LZrbYH4t9ctu8NZFGyuDlsOMH6k+ADLyzXV9wzn3sj1WS75wr9rP6V/HOVqwwsx/jnel4t/+8J5xz95jZN4CvOOcuNLNFwLnOuY1mluW8sWBE2owyeDnsOG+89DHAdUAR8IKZfTPmaWPxLvAw1R9692qgX8Tjz0X8P9G/PRV4ysz+B2+MEpE2lbLnp4gEj3OuHpgETPIz76tjnmJ4FwL5WnOziL3tnLvBzE7AG9hsjpmNcc5t279rLtJyyuDlsGNmQ8xsUMSkY4G1QDne5f8ApgPjIurrmWY2OOI1X434P81/zpHOuRnOubvwjgwih5AVOeCUwcvhqAPwJzPLAurwRg28Dvga8I6ZbXLOneaXbZ4zs3b+6+7EGzEQINvMFgLV/usAHvB3HIY3ouWCA/JuRJqhRlaRvRTZGNvW6yKyOyrRiIgElDJ4EZGAUgYvIhJQCvAiIgGlAC8iElAK8CIiAaUALyISUP8PFzuUyn0pspAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv3VHD585lc9"
      },
      "source": [
        "## Тестировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD6M4tb8l2Vs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a431f1fc-baf7-42a7-fd03-f2d961f28f36"
      },
      "source": [
        "model.eval()\n",
        "input_ids = tokenizer.encode(\"WebNLG: student | hometown | Moscow && student | play |  football </s>\", return_tensors=\"pt\")  # Batch size 1\n",
        "input_ids=input_ids.to(dev)\n",
        "outputs = model.generate(input_ids)\n",
        "tokenizer.decode(outputs[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> Moscow is the hometown of student, who play football.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owrlOe0L62WK"
      },
      "source": [
        "Для начала научимся версионализировать модели и загружать их\n",
        "Это хорошая практика для работы "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'pytoch_model.bin')"
      ],
      "metadata": {
        "id": "a0qpttuI8qzI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json"
      ],
      "metadata": {
        "id": "J1mBUK3L822m",
        "outputId": "7f744e61-9700-4781-fa81-835b80c8da29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-19 21:40:05--  https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.133.165\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.133.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1199 (1.2K) [application/json]\n",
            "Saving to: ‘t5-base-config.json.1’\n",
            "\n",
            "t5-base-config.json 100%[===================>]   1.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-19 21:40:05 (69.3 MB/s) - ‘t5-base-config.json.1’ saved [1199/1199]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Имея сохраненную модель и базовый конфиг, мы можем загрузить модель для дальнейшей работы"
      ],
      "metadata": {
        "id": "jXBzfEcm9QwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('pytoch_model.bin', return_dict=True,config='t5-base-config.json')"
      ],
      "metadata": {
        "id": "lr0qVi8W9QCS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец перейдем к тестировки модели, поиграемся немного"
      ],
      "metadata": {
        "id": "g7OFZxgI9pfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(text):\n",
        "  model.eval()\n",
        "  input_ids = tokenizer.encode(\"WebNLG:{} </s>\".format(text), return_tensors=\"pt\")  # Batch size 1\n",
        "  # input_ids.to(dev)\n",
        "  s = time.time()\n",
        "  outputs = model.generate(input_ids)\n",
        "  gen_text=tokenizer.decode(outputs[0]).replace('<pad>','').replace('</s>','')\n",
        "  elapsed = time.time() - s\n",
        "  print('Generated in {} seconds'.format(str(elapsed)[:4]))\n",
        "\n",
        "  \n",
        "  return gen_text"
      ],
      "metadata": {
        "id": "BbpB0q7R9k-W"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Real Madrid | wins | Champions_league')"
      ],
      "metadata": {
        "id": "DWj5UehI90El",
        "outputId": "cefb7729-d127-4229-ed97-208085c09514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.60 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Real Madrid won the Champions League.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Ivanov | profession | Doctor  && Ivanov | home_town |  Ivanovo')"
      ],
      "metadata": {
        "id": "FX_m4aqn-MEf",
        "outputId": "87062916-6fe8-4f8f-b1be-ba9d73ebd04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.13 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Ivanovo is home to Ivanov, a doctoral doctor.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('notebook | owner | Mugadzhir')"
      ],
      "metadata": {
        "id": "nPCm7MAR-3GC",
        "outputId": "ae04d151-c20e-4220-c34c-f1e255d004db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.15 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Mugadzhir is the owner of the book, which is owned by Mugad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('Akaev | make_food | very_bad')"
      ],
      "metadata": {
        "id": "bOloJ5ICBkt8",
        "outputId": "5f94aeed-86fc-4f46-8318-93e6baedb709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.27 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Akaev is a dish that makes a very bad food.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('stage | activate_prepare | script')"
      ],
      "metadata": {
        "id": "Ch1yIQzo_FJk",
        "outputId": "b25028ed-b4dd-4166-c197-d5019e433b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.87 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The script is the script for the active preparation of the stage.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HU1PfV-pA8lO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем квантизировать нашу модель и сравнить результаты"
      ],
      "metadata": {
        "id": "npkealI2CRDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization\n",
        "import torch.nn as nn\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {nn.Linear,nn.Dropout,nn.LayerNorm}, dtype=torch.qint8\n",
        ")"
      ],
      "metadata": {
        "id": "bmQjR1RICWpf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)\n",
        "print_size_of_model(quantized_model)"
      ],
      "metadata": {
        "id": "TjuZhhauCa05",
        "outputId": "2d8cfb88-f47e-481a-b66b-60cf7a41c468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 891.728959\n",
            "Size (MB): 322.018489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим разницу в размере модели после квантирования"
      ],
      "metadata": {
        "id": "oGFZ_zRSCkbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quant_generate(text):\n",
        "  quantized_model.eval()\n",
        "  input_ids = tokenizer.encode(\"WebNLG:{} </s>\".format(text), return_tensors=\"pt\")  # Batch size 1\n",
        "  # input_ids.to(dev)\n",
        "  s = time.time()\n",
        "  outputs = quantized_model.generate(input_ids)\n",
        "  gen_text=tokenizer.decode(outputs[0]).replace('<pad>','').replace('</s>','')\n",
        "  elapsed = time.time() - s\n",
        "  print('Generated in {} seconds'.format(str(elapsed)[:4]))\n",
        "\n",
        "  \n",
        "  return gen_text"
      ],
      "metadata": {
        "id": "KQY2vWBIChkL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_generate('VK | CEO | Durov  && VK | number Of Employees | 52000 ')"
      ],
      "metadata": {
        "id": "1WZgTIzmC1Eo",
        "outputId": "31cf254c-c7b4-41b7-a206-ce7886ce2d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 0.74 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The CEO of VK is Durov and there are 52000 people.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate('VK | CEO | Durov  && VK | number Of Employees | 52000 ')"
      ],
      "metadata": {
        "id": "wRbIOQbLC3Us",
        "outputId": "4005ff7b-4a7c-4415-86b6-8a4c86350388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.10 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' VK, which has 52000 employees, has a CEO named Durov.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_generate('Akaev | make_food | very_bad')"
      ],
      "metadata": {
        "id": "Af_034cYC7IM",
        "outputId": "61c33708-099b-475f-c0b7-f2c10b6697b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.13 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' AKAev is a dish made of a very bad food.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_generate('Real Madrid | wins | Champions_league')"
      ],
      "metadata": {
        "id": "2cY2z1-JJDiw",
        "outputId": "ad5a0b26-4a66-42fd-ec20-d6cfd8378609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.48 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The champions league of Real Madrid are the winners of the league.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_generate('Ivanov | profession | Doctor  && Ivanov | home_town |  Ivanovo')"
      ],
      "metadata": {
        "id": "qs0d_DHmGqCQ",
        "outputId": "f740b4e2-7c8b-43b6-8c8a-f0f38964336d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.56 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The doctoral Ivanov, whose profession is Doctor, is a doctor in I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_generate('notebook | owner | Mugadzhir')"
      ],
      "metadata": {
        "id": "GgsMkFO5Vy5d",
        "outputId": "ec79ecf7-a4cc-40ee-b194-6f9810ebe6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.32 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The owner of the book, The Mugadzhir, is the owner of the note'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_generate('stage | activate_prepare | script')"
      ],
      "metadata": {
        "id": "K1wP6qsxV8KI",
        "outputId": "ad4e065d-f21f-4c42-9735-85192accb964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated in 1.23 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The script is the script of the stage, which is the stage of the activation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YE46i5Y0WE42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}